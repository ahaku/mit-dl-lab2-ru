{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT_Music_Generation_RU.ipynb\"",
      "provenance": [],
      "collapsed_sections": [
        "uoJsVjtCMunI"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okyandex/mit-dl-lab2-ru/blob/main/MIT_Music_Generation_RU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoJsVjtCMunI"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/mit.png\" style=\"padding-bottom:5px;\" />\n",
        "      Visit MIT Deep Learning</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/aamini/introtodeeplearning/blob/master/lab1/solutions/Part2_Music_Generation_Solution.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/aamini/introtodeeplearning/blob/master/lab1/solutions/Part2_Music_Generation_Solution.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
        "</table>\n",
        "\n",
        "# Copyright Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUik05YqMyCH"
      },
      "source": [
        "# Copyright 2020 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n",
        "# \n",
        "# Licensed under the MIT License. You may not use this file except in compliance\n",
        "# with the License. Use and/or modification of this code outside of 6.S191 must\n",
        "# reference:\n",
        "#\n",
        "# © MIT 6.S191: Introduction to Deep Learning\n",
        "# http://introtodeeplearning.com\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-97SDET3JG-"
      },
      "source": [
        "# Лабораторная работа 1: Введение в TensorFlow и создание музыки с помощью рекуррентныx нейронных сетей (RNN)\n",
        "\n",
        "# Часть 2: Cоздание музыки с помощью RNN\n",
        "\n",
        "В этой части мы рассмотрим создание рекуррентной нейронной сети для генерации музыки. Мы научим модель находить шаблоны в нотах, представленных в [ABC-нотации](https://ru.wikipedia.org/wiki/ABC_(%D1%8F%D0%B7%D1%8B%D0%BA_%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%82%D0%BA%D0%B8)) и затем использовать её для создания музыки. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsvlBQYCrE4I"
      },
      "source": [
        "## 2.1 Зависимости\n",
        "Сначала загрузим репозиторий курса, установим зависимости и импортируем соответствующие пакеты, которые нам понадобятся для этой лабораторной работы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riVZCVK65QTH"
      },
      "source": [
        "# Импорт Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "\n",
        "# Загрузка и импорт MIT 6.S191 пакета\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "# Импорт остальных пакетов\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "# Проверьте, используете ли вы аппаратный ускоритель GPU.\n",
        "#   Среда выполнения > Сменить среду выполнения > GPU\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ajvp0No4qDm"
      },
      "source": [
        "## 2.2 Набор данных\n",
        "\n",
        "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)\n",
        "\n",
        "Мы собрали набор данных из тысяч ирландских народных песен, представленных в нотации ABC. Давайте загрузим набор данных и посмотрим на него:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7dFnP5q3Jve"
      },
      "source": [
        "# Загрузка набора данных\n",
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "# Распечатаем одну из песен, чтобы изучить ее более детально\n",
        "example_song = songs[0]\n",
        "print(\"\\nПример песни: \")\n",
        "print(example_song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKF3EHJlCAj2"
      },
      "source": [
        "Мы можем легко преобразовать песню из формата ABC в звуковую волну и воспроизвести ее. Подождите, пока это преобразование запустится, это может занять некоторое время."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11toYzhEEKDz"
      },
      "source": [
        "# Конвертируем песню из нотации ABC в аудиофайл и прослушаем его\n",
        "mdl.lab1.play_song(example_song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vH24yyquwKQ"
      },
      "source": [
        "Одна важная вещь заключается в том, что эта нотация не просто содержит информацию о воспроизводимых нотах, но также содержит метаинформацию, такую как название песни, тональность и темп. Как количество различных символов, присутствующих в текстовом файле, влияет на сложность задачи обучения? Это станет важным вскоре, когда мы создадим числовое представление для текстовых данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR"
      },
      "source": [
        "# Соединим наш список песен в одну строку, содержащую все песни\n",
        "songs_joined = \"\\n\\n\".join(songs) \n",
        "\n",
        "# Найдём все уникальные символы в объединённой строке\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"Уникальных символов в наборе данных: \", len(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## 2.3 Обработка набора данных для задачи обучения.\n",
        "\n",
        "Рассмотрим нашу задачу прогнозирования. Мы пытаемся обучить модель находить шаблоны в музыке, представленной в нотации ABC, а затем использовать эту модель для создания (т.е. прогнозирования) нового музыкального произведения на основе этой информации.\n",
        "\n",
        "На самом деле мы спрашиваем модель: учитывая символ или последовательность символов, какой наиболее вероятный следующий символ? Мы обучим модель выполнять эту задачу.\n",
        "\n",
        "Для этого мы передадим в модель последовательность символов и обучим модель предсказывать выходные данные, то есть следующий символ на каждом временном отрезке. RNN поддерживает внутреннее состояние, которое зависит от увиденных ранее символов, поэтому информация обо всех символах, увиденных до данного момента, будет учтена при создании прогноза."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### Векторизация текста\n",
        "До того как мы начнём обучать нашу RNN модель, нам нужно создать числовое представление нашего набора данных, основанного на буквах. Для этого мы создадим два словаря: один для перевода символов в числа, и второй для перевода чисел назад в символы. Напомним, что мы только что определили набор уникальных символов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IalZLbvOzf-F"
      },
      "source": [
        "### Определим числовое представление текста ###\n",
        "\n",
        "# Сделаем сопоставление символов и уникального индекса.\n",
        "# Например, чтобы получить индекс симова \"d\", \n",
        "#   мы можем выполнить `char2idx[\"d\"]`.  \n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "# Сделаем сопоставление от индексов к символам. Это работает наоборот\n",
        "# в отличии от char2idx и позволяет нам\n",
        "# по уникальному индексу получить символ в нашем словаре.\n",
        "idx2char = np.array(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfqhkYCymwX"
      },
      "source": [
        "Это даёт нам числовое представление каждого символа. Обратите внимание, что уникальные символы (то есть наш словарь) в тексте отображаются как индексы от 0 до `len(unique)`. Давайте взглянем на это числовое представление нашего набора данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYyNlCNXymwY"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
        "print('  ...\\n}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-LnKyu4dczc"
      },
      "source": [
        "### Векторизация строки с песнями ###\n",
        "\n",
        "''' TODO: Напишите функцию для преобразования строки, состоящей их всех песен в  \n",
        "    числовое представление. Исользуйте соответствующий словарь,\n",
        "    чтобы конвертировать текстовые символы в индексы.\n",
        "\n",
        "    NOTE: Функия `vectorize_string` должна возвращать \n",
        "    np.array с `N` элементами, где `N` это количество символов \n",
        "    во входной строке\n",
        "'''\n",
        "def vectorize_string(string):\n",
        "  vectorized_output = np.array([char2idx[char] for char in string])\n",
        "  return vectorized_output\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqxpSuZ1w-ub"
      },
      "source": [
        "Мы также можем посмотреть, как часть текста преображается в численное представление:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1VKcQHcymwb"
      },
      "source": [
        "print ('{} ---- Символы преобразованные в числа ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# Проверьте что vectorized_songs является массивом numpy\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"возвращаемый результат должен быть массивом numpy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Создание обучающих примеров и целей\n",
        "\n",
        "Наш следующий шаг - фактически разделить текст на примеры последовательностей, которые мы будем использовать во время обучения. Каждая последовательность, которую мы передадим в нашу сеть будет содержать кол-во символов в тексте `seq_length`. Нам также нужно будет определить целевую последовательность для каждой входной последовательности, которая будет использоваться при обучении сети для предсказания следующего символа. Для каждого входа соответствующая цель будет содержать текст одинаковой длины, за исключением смещения на один символ вправо.\n",
        "\n",
        "Для этого мы разобьем текст на куски (пакеты) длины `seq_length+1`. Предположим `seq_length` равна 4 и наш текст это \"Hello\". Тогда наша входная последовательность это \"Hell\" а целевая последовательность это \"ello\".\n",
        "\n",
        "Затем такой пакетный метод позволит нам преобразовать этот поток индексов символов в последовательности желаемого размера."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF-N8F7BoDRi"
      },
      "source": [
        "### Определение пакетов для создания обучающих примеров ###\n",
        "\n",
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # длина векторизированной строки с песнями\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  # случайным образом выбираем начальные индексы для примеров в обучающем пакете\n",
        "  idx = np.random.choice(n-seq_length, batch_size)\n",
        "\n",
        "  '''TODO: Создать список входных последовательностей для обучающего пакета'''\n",
        "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
        "\n",
        "  '''TODO: Создать список выходных последовательностей для обучающего пакета'''\n",
        "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
        "\n",
        "  # x_batch, y_batch предоставляют истинные данные и цели для обучения сети\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "\n",
        "# Выполним несколько простых тестов, чтобы убедиться, что функция\n",
        "# работает правильно \n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args): \n",
        "   print(\"======\\n[ОШИБКА] тесты не пройдены\")\n",
        "else: \n",
        "   print(\"======\\n[УСПЕХ] все тесты пройдены!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_33OHL3b84i0"
      },
      "source": [
        "Для каждого из этих векторов каждый индекс обрабатывается за один временной отрезок. Так, для входа на временном отрезке 0, модель получает индекс для первого символа в последовательности, и пытается предсказать индекс следующего символа. На следующем временном отрезке происходит то же самое, но RNN учитывает информацию с предыдущего шага, т.е. его обновленное состояние в дополнение к текущему вводу.\n",
        "\n",
        "Мы можем рассмотреть это более подробно, взглянув как это работает с первыми несколькими символами в нашем тексте:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eBu9WZG84i0"
      },
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Шаг {:3d}\".format(i))\n",
        "    print(\"  вход: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  ожидаемый выход: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## 2.4 Модель рекуррентной нейронной сети (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "Теперь мы готовы создать и обучить модель RNN на нашем наборе музыкальных данных (ABC-нотация), и затем использовать эту обученную модель для создания новой музыки. Мы будем обучать нашу RNN, используя пакеты фрагментов песен из нашего набора данных, которые мы создали в предыдущем разделе.\n",
        "\n",
        "Модель основана на архитектуре LSTM, где мы используем вектор состояния для сохранения информации о временных отношениях между последовательными символами. Окончательный выход LSTM затем подается в полносвязный [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) слой, выход которого будет обрабатываться с помощью функции softmax для каждого символа в словаре, а затем сделаем выборку из этого распределения, чтобы предсказать следующий символ.\n",
        "\n",
        "Как мы уже рассказали в первой части этой лабораторной работы, мы будем использовать Keras API, в частности, [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential), чтобы создать модель. Для определения модели используются три слоя:\n",
        "\n",
        "* [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding): Это входной слой, состоящий из таблицы, которая отображает номера каждого символа в вектор с размерностью `embedding_dim`.\n",
        "* [`tf.keras.layers.LSTM`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM): Наша LSTM сеть, с размером `units=rnn_units`. \n",
        "* [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense): Выходной слой, с выходным размером `vocab_size`.\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_unrolled-01-01.png\" alt=\"Drawing\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlaOqndqBmJo"
      },
      "source": [
        "### Создадим нашу RNN модель\n",
        "\n",
        "Теперь мы определим функцию, которую мы будем использовать для построения модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DsWzojvkbc7"
      },
      "source": [
        "def LSTM(rnn_units): \n",
        "  return tf.keras.layers.LSTM(\n",
        "    rnn_units, \n",
        "    return_sequences=True, \n",
        "    recurrent_initializer='glorot_uniform',\n",
        "    recurrent_activation='sigmoid',\n",
        "    stateful=True,\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbWU4dMJmMvq"
      },
      "source": [
        "Время пришло! Заполните TODO, чтобы создать модель RNN в функции build_model, а затем вызовите функцию, которую вы только что определили, чтобы создать экземпляр модели!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtCrdfzEI2N0"
      },
      "source": [
        "### Создание RNN модели ###\n",
        "\n",
        "'''TODO: Добавьте LSTM и Dense слои, чтобы создать RNN модель, \n",
        "    используя Sequential API.'''\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    # Слой 1: Embedding слой для преобразования индексов в dense векторы \n",
        "    #   фиксированного размера\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "\n",
        "    # Слой 2: LSTM с `rnn_units` количество единиц.\n",
        "    # TODO: Вызовите функцию LSTM, определенную выше, чтобы добавить этот слой.\n",
        "    LSTM(rnn_units), \n",
        "\n",
        "    # Слой 3: Dense (полносвязный) слой, который преобразует выход LSTM\n",
        "    #  в размер словаря. \n",
        "    # TODO: Добавьте Dense слой.\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Создайте простую модель с гиперпараметрами по умолчанию. Вы можете изменить\n",
        "#   их позже.\n",
        "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "### Проверьте модель RNN\n",
        "\n",
        "Всегда полезно выполнить несколько простых проверок нашей модели, чтобы убедиться, что она ведет себя так, как ожидалось.\n",
        "\n",
        "Во-первых, мы можем использовать функцию `Model.summary` чтобы вывести краткое содержание внутренней работы нашей модели. Здесь мы можем проверить слои в модели, форму выхода каждого из слоев, размер партии и т.д."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwG1DD6rDrRM"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xeDn5nZD0LX"
      },
      "source": [
        "Мы также можем быстро проверить размерность нашего выхода, используя длину последовательности 100. Обратите внимание, что модель может быть запущена на входах любой длины."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-_70kKAPrPU"
      },
      "source": [
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "pred = model(x)\n",
        "print(\"Входная форма:      \", x.shape, \" # (batch_size, sequence_length)\")\n",
        "print(\"Форма предсказания: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT1HvFVUGpoE"
      },
      "source": [
        "### Прогнозы от нетренированной модели\n",
        "\n",
        "Давайте посмотрим, что предсказывает наша нетренированная модель.\n",
        "Чтобы получить реальные прогнозы от модели, мы делаем выборку из выходного распределения, которое определяется функцией softmax по нашему словарю символов.\n",
        "Это даст нам фактические индексы символов. Это означает, что мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution) для выборки на примерах предсказания. Это дает предсказание следующего символа (в частности, его индекса) на каждом временном отрезке.\n",
        "\n",
        "Обратите внимание на то, что мы делаем выборку из этого распределения вероятностей, а не просто берём argmax, что может привести к застреванию модели в цикле.\n",
        "\n",
        "Давайте попробуем сделать выборку для первого примера в пакете."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Теперь мы можем их декодировать, чтобы увидеть текст, предсказанный нетренированной моделью:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcFwPwLSo05"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEHHcRasIDm9"
      },
      "source": [
        "Как вы можете заметить, текст, сгенерированный нетренированной моделью выглядит довольно бессмысленно. Как мы можем это улучшить? Мы можем обучить сеть!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## 2.5 Обучение модели: функция потерь и обучающие действия\n",
        "\n",
        "Пришло время обучить модель!\n",
        "\n",
        "На данный момент мы можем рассматривать задачу предсказывания следующего символа как обычную задачу классификации. Учитывая предыдущее состояние RNN, а также вход на данном временном отрезке, мы хотим предсказать класс следующего символа -- то есть фактически предсказать следующий символ. \n",
        "Чтобы обучить нашу модель для решения этой задачи классификации, мы можем использовать форму функции потерь `crossentropy` (negative log likelihood loss).\n",
        "В частности мы будем использовать функцию потерь [`sparse_categorical_crossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/backend/sparse_categorical_crossentropy), поскольку она использует целые числа для задач категориальной классификации. Мы хотим вычислить потери, используя истинные данные -- `labels` -- и прогнозируемые данные -- `logits`.\n",
        "\n",
        "Давайте сначала вычислим потери, используя наш пример прогнозов для нетренированной модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HrXTACTdzY-"
      },
      "source": [
        "### Создадим функцию потерь ###\n",
        "\n",
        "'''TODO: Создайте функцию, высчитывающую разницу между истинными данными\n",
        "   и предсказаниями (logits). Установите аргумент from_logits=True.'''\n",
        "def compute_loss(labels, logits):\n",
        "  loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "  return loss\n",
        "\n",
        "'''TODO: Вычислить потери, используя истинные данные о следующих символах \n",
        "   из тестового пакета и прогнозы нетренированной модели \n",
        "   несколькими ячейками выше'''\n",
        "example_batch_loss = compute_loss(y, pred)\n",
        "\n",
        "\n",
        "print(\"Форма предсказаний: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Seh7e6eRqd7"
      },
      "source": [
        "Начнем с определения некоторых гиперпараметров для обучения модели.Для начала мы установим разумные значения для некоторых параметров. Вы должны использовать то, чему научились в классе, чтобы оптимизировать выбор параметров здесь!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQWUUhKotkAY"
      },
      "source": [
        "### Настройка гиперпараметров и оптимизация ###\n",
        "\n",
        "# Оптимизация параметров:\n",
        "num_training_iterations = 2000  # Увеличьте это, чтобы модель дольше обучалась\n",
        "batch_size = 4  # Поэкспериментируйте со значениями от 1 до 64\n",
        "seq_length = 100  # Поэкспериментируйте со значениями от 50 до 500\n",
        "learning_rate = 5e-3  # Поэкспериментируйте со значениями от 1e-5 до 1e-1\n",
        "\n",
        "# Параметры модели: \n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256 \n",
        "rnn_units = 1024  # Поэкспериментируйте со значениями от 1 до 2048\n",
        "\n",
        "# Расположение контрольных точек: \n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cu11p1MKYZd"
      },
      "source": [
        "Теперь мы готовы определить оптимизатор и длительность обучения. Поэкспериментируйте с этими параметрами, чтобы увидеть как они влияют на выход нейронной сети. Некоторые оптимизаторы, которы вы можете попробовать это [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam?version=stable) и [`Adagrad`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adagrad?version=stable).\n",
        "\n",
        "Сначала мы создадим новую модель, а затем используем метод\n",
        "[`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) для обратного распространения ошибки. \n",
        "Мы так же будем выводить прогресс обучения модели, что поможет нам увидить уменьшаются ли ошибки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F31vzJ_u66cb"
      },
      "source": [
        "### Определите оптимизатор и обучающую операцию ###\n",
        "\n",
        "'''TODO: Создайте новую модель для обучения с помощью функции `build_model`\n",
        "   и гиперпараметров, определенных выше.'''\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "\n",
        "\n",
        "'''TODO: Создайте оптимизатор с указанием learning_rate.\n",
        "  Список поддерживаемых оптимизаторов можно найти на веб-сайте tensorflow.\n",
        "  https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/\n",
        "  Попробуйте для начала использовать оптимизатор Adam.'''\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y): \n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "  \n",
        "    '''TODO: Передайте вход в модель для генерации прогноза'''\n",
        "    y_hat = model(x) # TODO\n",
        "  \n",
        "    '''TODO: Вычислите потери!'''\n",
        "    loss = compute_loss(y, y_hat) # TODO\n",
        "\n",
        "  # Теперь вычислите градиенты\n",
        "  '''TODO: Помните, что мы хотим, чтобы градиент потерь учитывал \n",
        "     все параметры модели\n",
        "     HINT: Используйте `model.trainable_variables` чтобы получить список \n",
        "     всех параметров модели.'''\n",
        "  grads = tape.gradient(loss, model.trainable_variables) # TODO\n",
        "  \n",
        "  # Примените градиенты к оптимизатору, чтобы он мог \n",
        "  # соответствующим образом обновить модель\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "###################\n",
        "# Начало обучения!#\n",
        "###################\n",
        "\n",
        "history = []\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss')\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # очистить, если \n",
        "#'_instances' существует в tqdm\n",
        "\n",
        "for iter in tqdm(range(num_training_iterations)):\n",
        "\n",
        "  # Распространить пакет по сети\n",
        "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
        "  loss = train_step(x_batch, y_batch)\n",
        "\n",
        "  # Обновить индикатор выполнения\n",
        "  history.append(loss.numpy().mean())\n",
        "  plotter.plot(history)\n",
        "\n",
        "  # Обновить модель с изменёнными весами!\n",
        "  if iter % 100 == 0:     \n",
        "    model.save_weights(checkpoint_prefix)\n",
        "    \n",
        "# Сохранить обученную модель и веса\n",
        "model.save_weights(checkpoint_prefix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## 2.6 Создание музыки с помощью RNN модели\n",
        "\n",
        "Теперь мы можем создавать музыку с помощью нашей обученной модели! Что бы начать нам нужно передать в модель какой-нибудь seed (потому что модель не сможет ничего предсказать, если не с чего будет начать).\n",
        "\n",
        "Когда у нас будет сгенерированный seed мы сможем последовательно предсказать каждый последующий символ (помните, мы используем нотацию ABC для нашей музыки), используя обученную модель. В частности вспомним, что на выходе нашей RNN сети применяется функция `softmax` к возможным последовательным символам. Для вывода мы последовательно отбираем образцы из этих распределений, а затем используем наши образцы для кодирования сгенерированной песни в нотации ABC.\n",
        "\n",
        "Затем все, что нам нужно сделать, это записать это в файл и прослушать!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIPcXllKjkdr"
      },
      "source": [
        "### Восстановление последних контрольных точек.\n",
        "\n",
        "Чтобы упростить этот шаг, мы будем использовать размер пакета равным 1. Из-за того, как внутреннее состояние в RNN передается от шага к шагу, модель сможет принять фиксированный размер пакета только после её создания. \n",
        "\n",
        "Чтобы запустить модель с другим batch_size, нам нужно перестроить модель и восстановить веса из последней контрольной точки, то есть веса после последней контрольной точки во время обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LycQ-ot_jjyu"
      },
      "source": [
        "'''TODO: Перестройте модель, используя batch_size=1'''\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1) # TODO\n",
        "\n",
        "# Восстановите веса модели из последней контрольной точки после обучения\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9b4V2C8N62l"
      },
      "source": [
        "Обратите внимание, что мы передали фиксированный размер пакета `batch_size` равный 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "### Процедура прогнозирования\n",
        "\n",
        "Теперь мы готовы написать код для генерации текста в нотации ABC:\n",
        "\n",
        "* Инициализируйте начальную строку \"seed\" и состояние RNN, а также установите количество символов, которые мы хотим сгенерировать. \n",
        "\n",
        "* Используйте начальную строку и состояние RNN, чтобы получить распределение вероятностей для следующего предсказанного символа.\n",
        "\n",
        "* Получите выборку из полиномиального распределения для вычисления индекса предсказанного символа. Этот символ затем будет использован как следующий вход.\n",
        "\n",
        "* На каждом шаге обновленное состояние RNN возвращается в модель, так что теперь модель имеет больше контекста для следующего прогноза. После предсказания следующего символа обновленное состояние RNN снова передается в модель, и именно так она находит закономерности последовательностей в данных, поскольку получает больше информации из предыдущих предсказаний.\n",
        "\n",
        "![LSTM inference](https://raw.githubusercontent.com/aamini/introtodeeplearning/2019/lab1/img/lstm_inference.png)\n",
        "\n",
        "Поэкспериментируйте с некоторыми аспектами определения и обучения сети и завершите этот блок кода. И посмотрите, как работает модель. Как песни, созданные после обучения с небольшим количеством эпох отличаются от песен,  созданных после более длительного обучения?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvuwZBX5Ogfd"
      },
      "source": [
        "### Предсказание сгенерированной муызки ###\n",
        "\n",
        "def generate_text(model, start_string, generation_length=1000):\n",
        "  # Этап оценки (создание текста в нотации ABC, используя обученную модель)\n",
        "\n",
        "  '''TODO: Преобразуйте начальную строку в цифры (векторизация)'''\n",
        "  input_eval = [char2idx[s] for s in start_string] # TODO\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Пустая строка для хранения наших результатов\n",
        "  text_generated = []\n",
        "\n",
        "  # Размер пакета == 1\n",
        "  model.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(generation_length)):\n",
        "      '''TODO: оценить входные данные и сгенерировать\n",
        "         прогнозы для следующих символв'''\n",
        "      predictions = model(input_eval)\n",
        "      \n",
        "      # Удалить размерность пакета\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "      \n",
        "      '''TODO: используйте полиномиальное распределение для выборки'''\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "      \n",
        "      # Передайте прогноз вместе с предыдущим скрытым состоянием\n",
        "      #   в качестве следующих входов в модель\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      \n",
        "      '''TODO: добавить предсказанный символ к сгенерированному тексту!'''\n",
        "      # Hint: подумайте, в каком формате находится прогноз по сравнению с выходом\n",
        "      text_generated.append(idx2char[predicted_id]) # TODO \n",
        "    \n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktovv0RFhrkn"
      },
      "source": [
        "'''TODO: Используйте модель и функции, определенные выше, чтобы сгенерировать\n",
        "   текст в нотации ABC длиной 1000!\n",
        "   Как вы могли заметить файлы в нотации ABC начинаются \n",
        "   с символа \"X\" - это может быть хорошей начальной строкой.'''\n",
        "generated_text = generate_text(model, start_string=\"X\", generation_length=1000) # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "### Воспроизведите сгенерированную музыку!\n",
        "\n",
        "Теперь мы можем вызвать функцию для преобразования текса в нотации ABC в аудио файл, и прослушать его! Попробуйте обучать модель дольше, если полученная песня окажется недостаточно длинной, или заново сгенерируйте песню!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrOtG64bfLto"
      },
      "source": [
        "### Воспроизвести сгенерированные песни ###\n",
        "\n",
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs): \n",
        "  # Синтез песни\n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # Если это корректная песня (правильный синтаксис), давайте ее воспроизведем!\n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgVvcrYmSKGG"
      },
      "source": [
        "## 2.7 Экспериментируйте и **получайте награды за лучшие песни** !!\n",
        "\n",
        "Поздравляем с созданием вашей первой sequence модели с TensorFlow! Это довольно большое достижение, и, надеюсь, у вас есть какие-нибудь приятные мелодии, чтобы продемонстрировать их.\n",
        "\n",
        "Если хотите пойти дальше, попробуйте оптимизировать свою модель и представить свою лучшую песню! Напишите нам в Твиттере [@MITDeepLearning](https://twitter.com/MITDeepLearning) или [отправьте по email](mailto:introtodeeplearning-staff@mit.edu) копию песни (если у вас нет Твиттера), и мы раздадим призы нашим фаворитам!\n",
        "\n",
        "Подумайте, как вы можете улучшить свою модель и что кажется наиболее важным с точки зрения результата. Вот несколько идей для начала:\n",
        "\n",
        "*  Как количество эпох влияет на результат?\n",
        "*  Что, если вы измените или дополните набор данных? \n",
        "*  Сильно ли влияет выбор начальной строки на результат?\n",
        "\n",
        "Получайте удовольствие и приятного прослушивания!\n",
        "\n",
        "\n",
        "![Let's Dance!](http://33.media.tumblr.com/3d223954ad0a77f4e98a7b87136aa395/tumblr_nlct5lFVbF1qhu7oio1_500.gif)\n",
        "\n",
        "\n"
      ]
    }
  ]
}